{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import string\n",
    "import pickle \n",
    "import yaml\n",
    "import os\n",
    "import torch \n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = 'config.yaml'\n",
    "\n",
    "def text_preprocessing(text: str):\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove Punctuation\n",
    "    # text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    words = word_tokenize(text)  \n",
    "    # Remove Stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    ## Stemming\n",
    "    # porter = PorterStemmer()\n",
    "    # stemmed = [porter.stem(word) for word in filtered_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    \n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "def get_data_from_file(filename:str):\n",
    "\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_top_n_indices(array, top_n):\n",
    "    return array.argsort()[-top_n:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender():\n",
    "\n",
    "    def __init__(self, primary_column:str = 'title', top_n:int = 10) -> None:\n",
    "\n",
    "        # Open the configuration file to load parameters\n",
    "        with open(CONFIG_FILE, \"r\") as file:\n",
    "            try:\n",
    "                self.params = yaml.safe_load(file)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "        \n",
    "        self.top_n = top_n\n",
    "        self.primary_column = primary_column\n",
    "        metadata_file = self.params['METADATA_FILE']\n",
    "        self.metadata = pd.read_csv(metadata_file, index_col=0)\n",
    "        self.preprocess_metadata()\n",
    "        print(\"INFO: Initializing Model\")\n",
    "        self.model = SentenceTransformer('msmarco-distilbert-base-dot-prod-v3')\n",
    "        print(\"INFO: Creating embeddings\")\n",
    "        self.embeddings = self.get_embeddings(column=primary_column)\n",
    "        # self.product_feature_positiveness = get_data_from_file(self.params['product_feature_ratings'])\n",
    "\n",
    "\n",
    "    def preprocess_metadata(self) -> None:\n",
    "\n",
    "        self.metadata['description'] = self.metadata['description'].apply(lambda x: text_preprocessing(eval(x)[0]))\n",
    "\n",
    "    def get_embeddings(self, column) -> np.array:\n",
    "\n",
    "        # If embedding is locally saved already, load it \n",
    "        try:\n",
    "            with open(self.params['EMBEDDING_FILE'], 'rb') as file:\n",
    "                embeddings = pickle.load(file)\n",
    "            print(\"INFO : Loaded Product Embeddings\")\n",
    "            return embeddings\n",
    "        \n",
    "        # If embedding is not locally available, create embeddings\n",
    "        except:\n",
    "            print(\"INFO : Creating Embeddings\")\n",
    "            if torch.cuda.is_available():\n",
    "                embeddings = self.model.encode(self.metadata[column].tolist(), device='cuda') \n",
    "            else:\n",
    "                embeddings = self.model.encode(self.metadata[column].tolist())\n",
    "            embeddings = np.asarray(embeddings.astype('float32'))   \n",
    "            \n",
    "            print(\"INFO: Saving embeddings\")\n",
    "            if not os.path.exists(os.path.dirname(self.params['EMBEDDING_FILE'])):\n",
    "                os.mkdir(os.path.dirname(self.params['EMBEDDING_FILE']))\n",
    "            with open(self.params['EMBEDDING_FILE'],'wb') as file:\n",
    "                pickle.dump(embeddings, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            return embeddings\n",
    "\n",
    "    def return_most_similar(self, query):\n",
    "\n",
    "        print(\"INFO: Retrieving items for query\")\n",
    "        query_vector = self.model.encode([query])\n",
    "        similarity = np.dot(self.embeddings,query_vector.T)\n",
    "        top_items = similarity.flatten().argsort()[-self.top_n:][::-1]\n",
    "        print(self.metadata['title'].iloc[top_items])\n",
    "        return list(top_items), list(self.metadata['title'].iloc[top_items])\n",
    "\n",
    "\n",
    "    def character_similarity(self, character_list:list, subset_indices:list, method:int = 1):\n",
    "\n",
    "        # Method 1 - Join all characteristics to make an expanded query\n",
    "        if method == 1 :\n",
    "            character_query = ' '.join(character_list)\n",
    "            character_query_vector = self.model.encode(character_query)\n",
    "            similarity = np.dot(self.embeddings[subset_indices],character_query_vector.T)\n",
    "            # top_items =  get_top_n_indices(similarity.flatten(), self.top_n)       \n",
    "            return similarity / np.linalg.norm(similarity)\n",
    "\n",
    "        # Method 2 - Rank items based on individual characteristics\n",
    "        elif method == 2:\n",
    "            similarity_list =[]\n",
    "            for characteristic in character_list:\n",
    "                character_vector = self.model.encode(characteristic)\n",
    "                similarity = np.dot(self.embeddings[subset_indices],character_vector.T)\n",
    "                # top_items_list.append(get_top_n_indices(similarity.flatten(), top_n=200)) \n",
    "                similarity_list.append(similarity.flatten() / np.linalg.norm(similarity.flatten())) \n",
    "            agg_similarity = np.array(similarity_list).mean(axis=0)\n",
    "            return agg_similarity\n",
    "        \n",
    "    def feature_similarity(self, feature_imp):\n",
    "\n",
    "        agg_feature_poitiveness = np.zeros(self.product_feature_positiveness.shape()[0])\n",
    "        for ind, imp in enumerate(feature_imp):\n",
    "            agg_feature_poitiveness += imp*self.product_feature_positiveness[ind]\n",
    "        return agg_feature_poitiveness\n",
    "\n",
    "\n",
    "    def return_most_similar_v1(self, query:str, character_list:list, character_method:int, feature_imp:list = None):\n",
    "\n",
    "        print(\"INFO: Retrieving items for query\")\n",
    "        query_vector = self.model.encode([query + ' '.join(character_list)])\n",
    "        query_similarity = np.dot(self.embeddings,query_vector.T).flatten()\n",
    "        query_similarity  /= np.linalg.norm(query_similarity)\n",
    "        final_similarity = query_similarity\n",
    "        indices = get_top_n_indices(final_similarity, 10)\n",
    "        # character_similarity = self.character_similarity(character_list, method=1)\n",
    "        # feature_similarity = self.feature_similarity(feature_imp)\n",
    "\n",
    "        return indices\n",
    "                 \n",
    "\n",
    "    def get_top_items_for_features(top_n):\n",
    "        \n",
    "        self\n",
    "        final_product_embeddings = self.product_feature_ratings.mean(axis=1)\n",
    "        top_item_ind = get_top_n_indices(final_product_embeddings, top_n=5)\n",
    "        return top_item_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Initializing Model\n",
      "INFO: Creating embeddings\n",
      "INFO : Loaded Product Embeddings\n"
     ]
    }
   ],
   "source": [
    "recommender = Recommender(primary_column='description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Fangsto Women's Cowhide Leather Loafers Flats Sandals Slip-On\",\n",
       " \"Skechers USA Men's Caswell Oxford\",\n",
       " \"Roper Women's Lace and Underlay Western Boot\",\n",
       " \"Jambu Women's Pecan Mary Jane Flat\",\n",
       " \"KEEN Women's Terradora Mid Wp-w Hiking Boot\",\n",
       " \"JARO VEGA Women's Soft Goatskin Genuine Leather Pumps Slender Block Heel Closed Almond Toe Dress Shoes\",\n",
       " \"FRYE Women's Patty Artisan Zip Bootie\",\n",
       " \"ECCO Men's Soft 7 Fashion Sneaker\",\n",
       " \"Easy Spirit Women's Realflex Walking Shoe\",\n",
       " \"ASICS Women's GT-2000 3 Running Shoe\"]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Women leather shoes'\n",
    "\n",
    "# Query similarity\n",
    "query_similarity = np.dot(recommender.embeddings,recommender.model.encode([query]).T).flatten()\n",
    "query_similarity  /= np.linalg.norm(query_similarity)\n",
    "\n",
    "query_top_20 = get_top_n_indices(query_similarity, 20)\n",
    "# indices = get_top_n_indices(final_similarity, 20)\n",
    "\n",
    "character_list = ['Women', 'Leather']\n",
    "character_similarity = recommender.character_similarity(character_list=character_list, subset_indices=query_top_20, method=1)\n",
    "\n",
    "final_similarity = character_similarity\n",
    "sub_indices = get_top_n_indices(final_similarity, 10)\n",
    "main_indices = query_top_20[sub_indices]\n",
    "recommender.metadata['title'].iloc[main_indices].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Retrieving items for query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SoftSpots Perri Women&rsquo;s Slip-On',\n",
       " \"Blue Q Men's Crew Socks - Fits Men's Shoe Size 7-12\",\n",
       " \"Lacoste Men's Malahini Deck 316 1 Spm Fashion Sneaker\",\n",
       " 'In Touch Bamboo Above The Knee Skirt',\n",
       " \"Clarks Women's Daelyn Summit Slip-On Loafer\",\n",
       " \"Luichiny Women's Case Closed Snow Boot\",\n",
       " \"Steve Madden Women's Pierce Ankle Bootie\",\n",
       " \"Muck Boot Women's Breezy Low Boot\",\n",
       " \"Skechers Sport Women's Scene Stealer Fashion Sneaker\",\n",
       " 'Soft Jersey Blend Sleep Hat Comfortable Soft Hat Liner Beanie Skull Cap Chemo Hair Loss Head Covering']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Women's shoes\"\n",
    "character_list = ['Shiny', 'Sexy', 'Black']\n",
    "recommender.metadata['title'].iloc[recommender.return_most_similar_v1(query=query, character_list=character_list, character_method=1)].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4266, 1967, 1929, 4669, 4094, 2543, 2580,  896, 1814, 4878])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Avery Hill Boys Shiny Or Matte Patent Leather Special Occasion Christening Shoes',\n",
       " 'Jumping Jacks Destiny Ballet Flat (Toddler/Little Kid/Big Kid)',\n",
       " \"Jambu Women's Pecan Mary Jane Flat\",\n",
       " 'Polo Ralph Lauren Ankle Sport Socks 6-Pack',\n",
       " \"Lacoste Men's Malahini Deck 316 1 Spm Fashion Sneaker\",\n",
       " \"Bloch Dance Women's Jazzsoft Split Sole Leather Jazz Shoe\",\n",
       " \"ECCO Men's BIOM Hydromax Golf Shoe\",\n",
       " \"Skechers Men's Diameter-Guy Thing Oxford Sneaker\",\n",
       " \"UGG Men's Hendren Tl Winter Boot\",\n",
       " 'SoftSpots Perri Women&rsquo;s Slip-On']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crocs A Leigh 2-Strap Miniwedge',\n",
       " \"Womens Soft Leather Cigarette Case Holds Regular and 100's USA Made\",\n",
       " \"Cole Haan Men's Calhoun Lace-Up Derby Shoe\",\n",
       " \"Geox Men's Federico 9 Shoe\",\n",
       " \"Skechers USA Men's Caswell Oxford\",\n",
       " 'Woly German Suede Nubuck Brush 5&quot; Removes Dirt &amp; Stains on Designer Shoes, Boots, Handbags, Clothes.',\n",
       " \"Birkenstock Women's Madrid Birko-Flor Sandal\",\n",
       " \"Lucky Women's Galvann\",\n",
       " 'Collonil Nubuck + Velours/Suede Waterproof Protector Repellent Spray, 200 ml',\n",
       " \"Fangsto Women's Cowhide Leather Loafers Flats Sandals Slip-On\"]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.metadata['title'].iloc[get_top_n_indices(character_similarity, 10)].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SoftSpots Perri Women&rsquo;s Slip-On',\n",
       " \"Lacoste Men's Malahini Deck 316 1 Spm Fashion Sneaker\",\n",
       " \"Rocket Dog Women's Rainy Rubber Rain Boot\",\n",
       " \"Clarks Women's Blanche Nora Ballet Flat\",\n",
       " \"Bloch Dance Women's Jazzsoft Split Sole Leather Jazz Shoe\",\n",
       " 'Teva Scamper Water Shoe (Toddler/Little Kid/Big Kid)',\n",
       " \"Ollio Women's Shoe Cross Braided Multi Color Flat Sandal\",\n",
       " 'Adidas Pretereo 2 Wrestling Shoes - Collegiate Royal/White/Black',\n",
       " \"Dr. Martens Men's Octavius Lace Shoe\",\n",
       " \"New Balance Women's Minimus Sport Spikeless Golf Shoe\"]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.metadata['title'].iloc[get_top_n_indices(query_similarity, 10)].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
